{
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "sessionKeepAliveTimeout": 30
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Azure Cosmos DB の API for MongoDB と Synapse Link をはじめる\n",
        "\n",
        "このサンプルでは、次のタスクを実行します:\n",
        "\n",
        "1. 従来の MongoDB クライアントを使用してデータセットを挿入します。  \n",
        "1. 挿入したトランザクションデータから、分析ストアに対して集計クエリを実行します。\n",
        "1. MongoSpark コネクタを使用し、別のデータセットを挿入します。\n",
        "1. 両方のデータセットを統合して、集計クエリを再度実行します。\n",
        "\n",
        "## 前提条件\n",
        "1. Azure Cosmos DB で MongoDB API アカウントを作成しましたか？そうでない場合は、[Azure Cosmos DB の API for MongoDB のアカウントを作成する](https://docs.microsoft.com/azure/cosmos-db/create-cosmosdb-resources-portal#create-an-azure-cosmos-db-account)に移動します。API オプションとして MongoDB を使用してアカウントを作成してください。\n",
        "1. Cosmos DBアカウントで、Synapse Link を有効にしましたか？そうでない場合は、[Azure Cosmos DB アカウントの Synapse Link を有効にする](https://docs.microsoft.com/azure/cosmos-db/configure-synapse-link#enable-synapse-link)に移動します。\n",
        "1. Synapse ワークスペースを作成しましたか？そうでない場合は、[Synapse ワークスペースの作成](https://docs.microsoft.com/azure/synapse-analytics/quickstart-create-workspace)に移動します。\n",
        "\n",
        "## Synapse Link を使用して Cosmos DB コレクションを作成する \n",
        "1. `test` という名前のデータベースを作成します。\n",
        "1. `pk` というパーティションキーを使用して、 `htap` という名前のコレクションを作成します。\n",
        "    - コレクションを作成するときは、必ず `Analytical store` (分析ストア)オプションを `On` に設定してください。\n",
        "\n",
        "## コレクションを Synapse に接続する\n",
        "1. Synapse Analytics ワークスペースに移動します。\n",
        "1. MongoDB API アカウントの `Linked Data` 接続を作成します。\n",
        "    1. `Data` ブレードの下で、+ (プラス) 記号を選択します。\n",
        "    1. `Connect to external data` オプションを選択します。\n",
        "    1. 次に `Azure Cosmos DB (MongoDB API)` オプションを選択します。\n",
        "    1. ドロップダウンを使用するか、接続文字列を入力して、特定の Azure Cosmos DB アカウントに関するすべての情報を入力します。`Linked Data` 接続に割り当てた名前をメモしておいてください。\n",
        "    - または、アカウントの概要にある接続パラメータ＝を使用することもできます。\n",
        "1. `Data` ブレードの `Linked` タブでデータベースアカウントを探し、接続をテストします。\n",
        "    - すべてのアカウントとコレクションを含むリストがあるはずです。\n",
        "    - `Analytical Store` が有効になっているコレクションには、特有のアイコンが表示されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 環境を整えましょう\n",
        "\n",
        "この環境では、実行する Python ライブラリをインストールして使用できます。このサンプルでは、次のライブラリを Spark プールに追加する必要があります:\n",
        "\n",
        "```\n",
        "pymongo==2.8.1\n",
        "aenum==2.1.2\n",
        "backports-abc==0.5\n",
        "bson==0.5.10\n",
        "```\n",
        "\n",
        "ライブラリを Spark プールにインポートする方法については、[こちらの記事](https://docs.microsoft.com/ja-jp/azure/synapse-analytics/spark/apache-spark-azure-portal-add-libraries)をご覧ください。このための新しい Spark プールを作成することを推奨します。\n",
        "\n",
        "次のコマンドを実行し、すべてのライブラリが正しくインストールされたことを確認します:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "MongoSpark",
              "session_id": 11,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-08-19T21:30:36.2458227Z",
              "execution_start_time": "2020-08-19T21:33:21.3955312Z",
              "execution_finish_time": "2020-08-19T21:33:23.4516169Z"
            },
            "text/plain": "StatementMeta(MongoSpark, 11, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "zipp 0.6.0\nzict 1.0.0\nxlwt 1.2.0\nXlsxWriter 0.9.6\nxlrd 1.0.0\nwrapt 1.11.2\nwidgetsnbextension 2.0.0\nwheel 0.30.0\nWerkzeug 0.16.0\nwebsocket-client 0.56.0\nwcwidth 0.1.7\nvega-datasets 0.7.0\nurllib3 1.25.6\nunicodecsv 0.14.1\ntyping-extensions 3.7.4\ntraitlets 4.3.2\ntqdm 4.48.2\ntornado 6.0.3\ntorch 1.3.0\ntoolz 0.10.0\ntestpath 0.3\nterminado 0.6\ntermcolor 1.1.0\ntensorflow 1.14.0\ntensorflow-estimator 1.14.0\ntensorboard 1.14.0\ntblib 1.4.0\ntables 3.3.0\nsympy 1.0\nstatsmodels 0.10.1\nSQLAlchemy 1.1.9\nspyder 3.1.4\nsortedcontainers 2.1.0\nsortedcollections 0.5.3\nsnowballstemmer 1.2.1\nsmart-open 1.8.4\nsklearn-pandas 1.7.0\nskl2onnx 1.4.9\nsix 1.12.0\nsingledispatch 3.4.0.3\nsimplegeneric 0.8.1\nshap 0.34.0\nsetuptools 41.4.0\nSecretStorage 3.1.1\nseaborn 0.9.0\nscipy 1.1.0\nscikit-learn 0.20.3\nscikit-image 0.15.0\ns3transfer 0.2.1\nruamel.yaml 0.15.89\nrope-py3k 0.9.4.post1\nretrying 1.3.3\nResource 0.2.1\nrequests 2.22.0\nrequests-oauthlib 1.2.0\nQtPy 1.2.1\nqtconsole 4.3.0\nQtAwesome 0.4.4\npyzmq 16.0.2\nPyYAML 5.1.2\nPyWavelets 1.0.3\npytz 2019.3\nPython-EasyConfig 0.1.7\npython-dateutil 2.8.0\npytest 3.0.7\npyspark 2.4.4\npyrsistent 0.15.4\npyparsing 2.4.2\npyOpenSSL 19.0.0\npyodbc 4.0.16\npymssql 2.1.4\npylint 1.6.4\nPyJWT 1.7.1\nPygments 2.2.0\npygal 2.4.0\npyflakes 2.1.1\npycurl 7.43.0\npyct 0.4.6\npycrypto 2.6.1\npycparser 2.19\npycosat 0.6.2\npycodestyle 2.5.0\npyasn1 0.4.7\npyarrow 0.15.1\npy4j 0.10.7\npy 1.4.33\npy-cpuinfo 5.0.0\nptyprocess 0.5.1\npsutil 5.2.2\nprotobuf 3.10.0\nprompt-toolkit 2.0.10\nportalocker 1.7.1\npmdarima 1.1.1\nply 3.10\nplotly 4.1.1\npip 9.0.1\nPillow 6.2.0\npickleshare 0.7.4\npexpect 4.2.1\npep8 1.7.0\npatsy 0.5.1\npathspec 0.6.0\npathlib2 2.2.1\npartd 1.0.0\nparam 1.9.2\npandocfilters 1.4.1\npandas 0.23.4\npackaging 19.2\nopenpyxl 2.4.7\nonnxruntime 0.4.0\nonnxmltools 1.4.1\nonnxconverter-common 1.5.5\nonnx 1.6.0\nolefile 0.44\nodo 0.5.0\noauthlib 3.1.0\nnumpydoc 0.6.0\nnumpy 1.16.2\nnumexpr 2.6.2\nnumba 0.33.0\nnotebookutils 20200701.5\nnotebook 5.0.0\nnose 1.3.7\nnltk 3.2.3\nnimbusml 1.5.0\nnetworkx 2.3\nndg-httpsclient 0.5.1\nnbformat 4.3.0\nnbconvert 5.1.1\nnavigator-updater 0.1.0\nmultipledispatch 0.4.9\nmultimethods 1.0.0\nmsrestazure 0.6.2\nmsrest 0.6.10\nmsgpack 0.6.2\nmsgpack-python 0.4.8\nmsal 1.4.3\nmsal-extensions 0.1.3\nmpmath 0.19\nmore-itertools 7.2.0\nmmlspark 1.0.0.dev1\nmistune 0.7.4\nmissingno 0.4.2\nmccabe 0.6.1\nmatplotlib 3.1.1\nMarkupSafe 1.1.1\nMarkdown 3.1.1\nlxml 3.7.3\nlocket 0.2.0\nllvmlite 0.18.0\nlightgbm 2.2.3\nliac-arff 2.4.0\nlazy-object-proxy 1.2.2\nkiwisolver 1.1.0\nkeras2onnx 1.5.2\nKeras-Preprocessing 1.1.0\nKeras-Applications 1.0.8\njupyter 1.0.0\njupyter-core 4.3.0\njupyter-console 5.1.0\njupyter-client 5.0.1\nJsonSir 0.0.2\njsonschema 3.1.1\njsonpickle 1.2\nJsonForm 0.0.2\njson-logging-py 0.2\njoblib 0.14.1\njmespath 0.9.4\nJinja2 2.10.3\njeepney 0.4.1\njedi 0.10.2\njdcal 1.3\nitsdangerous 0.24\nisort 4.2.5\nisodate 0.6.0\nipywidgets 6.0.0\nipython 7.8.0\nipython-genutils 0.2.0\nipykernel 4.6.1\ninterpret-core 0.1.21\ninterpret-community 0.10.2\nimportlib-metadata 0.23\nimagesize 0.7.1\nimageio 2.6.1\nidna 2.8\nhyperspace 0.0.1\nhtml5lib 0.999\nHeapDict 1.0.1\nh5py 2.10.0\ngunicorn 19.9.0\ngrpcio 1.24.1\ngreenlet 0.4.12\ngoogle-pasta 0.1.7\ngevent 1.2.1\ngensim 3.8.1\ngast 0.3.2\nfusepy 3.0.1\nfsspec 0.5.2\nFlask 1.0.3\nFlask-Cors 3.0.2\nflake8 3.7.9\nfire 0.2.1\nfastcache 1.0.2\net-xmlfile 1.0.1\nentrypoints 0.3\ndotnetcore2 2.1.14\ndocutils 0.15.2\ndocker 4.1.0\ndistro 1.4.0\ndistributed 1.16.3\ndill 0.3.1.1\ndecorator 4.4.0\ndatashape 0.5.4\ndask 0.14.3\ncytoolz 0.8.2\nCython 0.29.13\ncycler 0.10.0\ncryptography 2.7\ncontextlib2 0.6.0.post1\nconfigparser 3.7.4\ncolorama 0.3.9\nclyent 1.2.2\ncloudpickle 1.2.2\nclick 6.7\nchart-studio 1.0.0\nchardet 3.0.4\ncffi 1.12.3\ncertifi 2019.9.11\nBottleneck 1.2.1\nbotocore 1.12.247\nboto3 1.9.247\nboto 2.49.0\nbokeh 1.3.4\nbleach 1.5.0\nblaze 0.10.1\nbitarray 0.8.1\nbeautifulsoup4 4.6.0\nbackports.weakref 1.0.post1\nbackports.tempfile 1.0\nbackports.shutil-get-terminal-size 1.0.0\nbackcall 0.2.0\nBabel 2.4.0\nazureml-train 1.6.0\nazureml-train-restclients-hyperdrive 1.6.0\nazureml-train-core 1.6.0\nazureml-train-automl 1.6.0\nazureml-train-automl-runtime 1.6.0\nazureml-train-automl-client 1.6.0.post1\nazureml-telemetry 1.6.0\nazureml-sdk 1.6.0\nazureml-pipeline 1.6.0\nazureml-pipeline-steps 1.6.0\nazureml-pipeline-core 1.6.0\nazureml-opendatasets 1.6.0\nazureml-model-management-sdk 1.0.1b6.post1\nazureml-interpret 1.6.0\nazureml-explain-model 1.6.0\nazureml-defaults 1.6.0\nazureml-dataprep 1.6.3\nazureml-dataprep-native 14.1.0\nazureml-core 1.6.0\nazureml-automl-runtime 1.6.0.post2\nazureml-automl-core 1.6.0\nazure-storage-common 2.1.0\nazure-storage-blob 2.1.0\nazure-mgmt-storage 4.2.0\nazure-mgmt-resource 5.1.0\nazure-mgmt-network 10.2.0\nazure-mgmt-keyvault 2.0.0\nazure-mgmt-containerregistry 2.8.0\nazure-mgmt-authorization 0.60.0\nazure-identity 1.2.0\nazure-graphrbac 0.61.1\nazure-core 1.7.0\nazure-common 1.1.23\nattrs 19.2.0\nastropy 1.3.2\nastroid 1.4.9\nastor 0.8.0\nasn1crypto 1.0.1\napplicationinsights 0.11.9\naltair 3.2.0\nalabaster 0.7.10\nadal 1.2.2\nabsl-py 0.8.1\nSphinx 1.5.6"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "outputCollapsed": true
      },
      "source": [
        "import pip #needed to use the pip functions\n",
        "\n",
        "for i in pip.get_installed_distributions(local_only=True):\n",
        "    print(i)\n",
        "\n",
        "# The output might be long... you can collapse it by clicking on the 'Collapse output' option on the upper left corner of the output cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### こちらにデータベースアカウント固有の秘匿情報を記述してください！\n",
        "\n",
        "誰にも教えないようにしてください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "MongoSpark",
              "session_id": 9,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-08-19T07:19:55.1572228Z",
              "execution_start_time": "2020-08-19T07:19:55.1953802Z",
              "execution_finish_time": "2020-08-19T07:19:57.2244591Z"
            },
            "text/plain": "StatementMeta(MongoSpark, 9, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "DATABASE_ACCOUNT_NAME = '<ここにテータベースアカウント名を入力します>'\n",
        "DATABASE_ACCOUNT_READWRITE_KEY = '<ここにプライマリまたはセカンダリパスワードを入力します>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MongoDB クライアントを初期化しましょう\n",
        "\n",
        "アカウントの概要から次のパラメータのみが必要になります: \n",
        "- 接続文字列。\n",
        "- プライマリまたはセカンダリの読み取り/書き込みキー。\n",
        "\n",
        "データベースには `test` 、コレクションには `htap` という名前を付けたことを思い出してください。\n",
        "\n",
        "以下のコードスニペットは、`MongoClient` オブジェクトを初期化する方法を示しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "MongoSpark",
              "session_id": 9,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-08-19T07:20:48.8352623Z",
              "execution_start_time": "2020-08-19T07:20:48.8750501Z",
              "execution_finish_time": "2020-08-19T07:20:50.9474208Z"
            },
            "text/plain": "StatementMeta(MongoSpark, 9, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pymongo'",
          "traceback": [
            "ModuleNotFoundError: No module named 'pymongo'",
            "Traceback (most recent call last):\n",
            "ModuleNotFoundError: No module named 'pymongo'\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "from pymongo import MongoClient\n",
        "from bson import ObjectId # ObjectId が機能するため\n",
        "\n",
        "client = MongoClient(\"mongodb://{account}.mongo.cosmos.azure.com:10255/?ssl=true&replicaSet=globaldb\".format(account = DATABASE_ACCOUNT_NAME)) # 独自のデータベースアカウントのエンドポイント。\n",
        "db = client.test    # データベースを選択\n",
        "db.authenticate(name=DATABASE_ACCOUNT_NAME,password=DATABASE_ACCOUNT_READWRITE_KEY) # データベースアカウント名と任意の読み取り/書き込みキーを使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MongoClient ドライバーを使用したデータの挿入\n",
        "\n",
        "次のサンプルは、ランダムデータに基づいて 500 アイテムを生成します。各アイテムには次のフィールドが含まれます:\n",
        "- Item, string\n",
        "- Price, float\n",
        "- Rating, integer\n",
        "- Timestamp, [epoch integer](http://unixtimestamp.50x.eu/about.php)\n",
        "\n",
        "このセルは、上記のセルに依存して、Cosmos DB MongoDB API アカウントへの接続のインスタンスを作成します。\n",
        "\n",
        "このデータは、データベースの MongoDB ストアに挿入されます。これは、アプリケーションが生成するトランザクションデータをエミュレートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from random import randint\n",
        "import time\n",
        "\n",
        "orders = db[\"htap\"]\n",
        "\n",
        "items = ['Pizza','Sandwich','Soup', 'Salad', 'Tacos']\n",
        "prices = [2.99, 3.49, 5.49, 12.99, 54.49]\n",
        "\n",
        "for x in range(1, 501):\n",
        "    order = {\n",
        "        'item' : items[randint(0, (len(items)-1))],\n",
        "        'price' : prices[randint(0, (len(prices)-1))],\n",
        "        'rating' : randint(1, 5),\n",
        "        'timestamp' : time.time()\n",
        "    }\n",
        "    \n",
        "    result=orders.insert(order)\n",
        "\n",
        "print('500 個の注文の作成が終了しました')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 分析ストアからデータを読み取る\n",
        "\n",
        "トランザクションデータを挿入したので、分析ストアからデータを読み取ってみましょう。\n",
        "\n",
        "データは自動的に列形式に変換されるため、大規模な集計クエリをすばやく簡単に実行できます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "session_starting",
              "livy_statement_state": null,
              "queued_time": "2020-08-21T08:19:55.7976362Z",
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , SessionStarting, )"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# 分析ストアのデータをデータフレームにロードする\n",
        "# シークレットを使用してセルを実行し、DATABASE_ACCOUNT_NAME および DATABASE_ACCOUNT_READWRITE_KEY 変数を取得します。\n",
        "df = spark.read.format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.cosmos.accountEndpoint\", \"https://{account}.documents.azure.com:443/\".format(account = DATABASE_ACCOUNT_NAME))\\\n",
        "    .option(\"spark.cosmos.accountKey\", DATABASE_ACCOUNT_READWRITE_KEY)\\\n",
        "    .option(\"spark.cosmos.database\", \"test\")\\\n",
        "    .option(\"spark.cosmos.container\", \"htap\")\\\n",
        "    .load()\n",
        "\n",
        "# ピザの注文からのすべての収益を調べてみましょう\n",
        "df.groupBy(df.item.string).sum().show()\n",
        "\n",
        "# df[df.item.string == 'Pizza'].show(10) \n",
        "# df.select(df['item'] == Struct).show(10) \n",
        "# df.select(\"timestamp.float64\").show(10)\n",
        "#df.select(\"timestamp.string\", when(df.timestamp.string != null)).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 分析ストアの MongoDB スキーマに関する簡単なメモ\n",
        "\n",
        "Mongoアカウントでは、 **完全な忠実度スキーマ**を使用します。これは、データ型で拡張されたプロパティ名の表現であり、値の正確な表現を提供し、あいまいさを回避します。\n",
        "これが、上記のフィールドを呼び出すときに、それらのデータ型をサフィックスとして使用した理由です。 以下の例のように:\n",
        "\n",
        "```\n",
        "df.filter((df.item.string == \"Pizza\")).show(10)\n",
        "```\n",
        "プロパティの名前の後に文字列型を指定したことに注意してください。 以下は、分析ストア内のすべての潜在的なプロパティとそれらのサフィックス表現のマップです:\n",
        "\n",
        "| Original Data Type     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| Suffix    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| Example &nbsp;&nbsp;&nbsp;&nbsp; | \n",
        "|---------------|----------------|--------|\n",
        "| Double        | \".float64\"     |  `24.99`   |\n",
        "| Array         | \".array\"       |  `[\"a\", \"b\"]`   |\n",
        "| Binary        | \".binary\"      |  `0`   |\n",
        "| Boolean       | \".bool\"        |  `True`   |\n",
        "| Int32         | \".int32\"       |  `123`   |\n",
        "| Int64         | \".int64\"       |  `255486129307`   |\n",
        "| Null          | \".null\"        |  `null`   |\n",
        "| String        | \".string\"      |  `\"ABC\"`   |\n",
        "| Timestamp     | \".timestamp\"   |  `Timestamp(0, 0)`   |\n",
        "| DateTime      | \".date\"        |  `ISODate(\"2020-08-21T07:43:07.375Z\")`   |\n",
        "| ObjectId      | \".objectId\"    |  `ObjectId(\"5f3f7b59330ec25c132623a2\")`   |\n",
        "| Document      | \".object\"      |  `{\"a\": \"a\"}`   |\n",
        "\n",
        "これらの型は、トランザクションストアに挿入されたデータから推測されます。 次のコマンドを実行してスキーマを確認できます:\n",
        "\n",
        "```\n",
        "df.schema\n",
        "```\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## さらに注文を入れましょう！\n",
        "\n",
        "今回は少し異なるデータを使用します。各アイテムには次のフィールドが含まれます:\n",
        "- Item, string\n",
        "- Price, float\n",
        "- Rating, integer\n",
        "- Timestamp, [ISO String format](https://en.wikipedia.org/wiki/ISO_8601)\n",
        "\n",
        "`Timestamp` フィールドが文字列形式になっていることに注意してください。これは、データタイプに基づいてさまざまなデータフィールドを読み取る方法を理解するのに役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from random import randint\n",
        "from time import strftime\n",
        "\n",
        "orders = db[\"htap\"]\n",
        "\n",
        "items = ['Pizza','Sandwich','Soup', 'Salad', 'Tacos']\n",
        "prices = [2.99, 3.49, 5.49, 12.99, 54.49]\n",
        "\n",
        "for x in range(1, 501):\n",
        "    order = {\n",
        "        'item' : items[randint(0, (len(items)-1))],\n",
        "        'price' : prices[randint(0, (len(prices)-1))],\n",
        "        'rating' : randint(1, 5),\n",
        "        'timestamp' : strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "    \n",
        "    result=orders.insert(order)\n",
        "\n",
        "print('500 個の注文の作成が終了しました')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 注文データをもう一度読み取りましょう！\n",
        "\n",
        "今回は、`timestamp.string` パラメーターを指定して、ISO 文字列の日付を個別に読み取ります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "MongoSpark",
              "session_id": 9,
              "statement_id": 27,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-08-19T08:14:33.1214303Z",
              "execution_start_time": "2020-08-19T08:14:33.168174Z",
              "execution_finish_time": "2020-08-19T08:14:37.245524Z"
            },
            "text/plain": "StatementMeta(MongoSpark, 9, 27, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "+--------------------+----------+--------------------+--------------------+--------------+----------+-------+------+--------------------+---+--------------+\n|                _rid|       _ts|                  id|               _etag|           _id|      item|  price|rating|           timestamp| pk| _partitionKey|\n+--------------------+----------+--------------------+--------------------+--------------+----------+-------+------+--------------------+---+--------------+\n|c8dVAMNlPsb1AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003909-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Tacos]|[12.99]|   [1]|[, 2020-08-18 23:...|[3]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb2AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003a09-0000-08...|[_<`��]\u001b\u001aRUj�]|[Sandwich]|[54.49]|   [5]|[, 2020-08-18 23:...|[1]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb3AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003b09-0000-08...|[_<`��]\u001b\u001aRUj�]|    [Soup]| [5.49]|   [4]|[, 2020-08-18 23:...|[4]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb4AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003c09-0000-08...|[_<`��]\u001b\u001aRUj�]|    [Soup]|[12.99]|   [1]|[, 2020-08-18 23:...|[4]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb5AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003d09-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Tacos]|[12.99]|   [2]|[, 2020-08-18 23:...|[2]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb6AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003e09-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Pizza]|[12.99]|   [3]|[, 2020-08-18 23:...|[2]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb7AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00003f09-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Salad]|[54.49]|   [5]|[, 2020-08-18 23:...|[2]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb8AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00004009-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Salad]| [3.49]|   [1]|[, 2020-08-18 23:...|[5]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb9AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00004109-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Salad]|[54.49]|   [1]|[, 2020-08-18 23:...|[5]|[c8dVAMNlPsY=]|\n|c8dVAMNlPsb+AQAAA...|1597792391|NWYzYzYwODdmYjVkM...|\"00004209-0000-08...|[_<`��]\u001b\u001aRUj�]|   [Salad]|[54.49]|   [1]|[, 2020-08-18 23:...|[5]|[c8dVAMNlPsY=]|\n+--------------------+----------+--------------------+--------------------+--------------+----------+-------+------+--------------------+---+--------------+\nonly showing top 10 rows"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# 分析ストアのデータをデータフレームにロードする\n",
        "# シークレットを使用してセルを実行し、DATABASE_ACCOUNT_NAME および DATABASE_ACCOUNT_READWRITE_KEY 変数を取得します。\n",
        "df = spark.read.format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.cosmos.accountEndpoint\", \"https://{account}.documents.azure.com:443/\".format(account = DATABASE_ACCOUNT_NAME))\\\n",
        "    .option(\"spark.cosmos.accountKey\", DATABASE_ACCOUNT_READWRITE_KEY)\\\n",
        "    .option(\"spark.cosmos.database\", \"test\")\\\n",
        "    .option(\"spark.cosmos.container\", \"htap\")\\\n",
        "    .load()\n",
        "\n",
        "# ピザの注文からのすべての収益を調べてみましょう\n",
        "df.filter( (df.timestamp.string != \"\")).show(10)"
      ]
    }
  ]
}