{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Query PARQUET files\n",
                "\n",
                "Serverless Synapse SQL pool enables you to read PARQUET files from Azure storage (DataLake or blob storage).\n",
                "\n",
                "## Read parquet file\n",
                "\n",
                "The easiest way to see to the content of your `PARQUET` file is to provide file URL to `OPENROWSET` function and specify parquet `FORMAT`. If the file is publicly available or if your Azure AD identity can access this file, you should be able to see the content of the file using the query like the one shown in the following example:"
            ],
            "metadata": {
                "azdata_cell_guid": "e01663cc-427c-457f-84db-b16d0fca3a90"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "select top 10 *\r\n",
                "from openrowset(\r\n",
                "    bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',\r\n",
                "    format = 'parquet') as rows"
            ],
            "metadata": {
                "azdata_cell_guid": "dbc4f12e-388c-49fa-9d85-0fbea3b19d1b"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Data source usage\n",
                "\n",
                "Previous example uses full path to the file. As an alternative, you can create an external data source with the location that points to the root folder of the storage, and use that data source and the relative path to the file in `OPENROWSET` function.\n",
                "\n",
                "First you need to create `EXTERNAL DATA SOURCE` in some database:"
            ],
            "metadata": {
                "azdata_cell_guid": "a373fa76-bfdf-4bb6-8098-73c9ef436eb8"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "create external data source covid\r\n",
                "with ( location = 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases' );"
            ],
            "metadata": {
                "azdata_cell_guid": "48b6ee55-09ec-47df-bea5-707dc2f42aa8"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "Make sure that you create `EXTERNAL DATA SOURCE` in database other than `master`. If data source is protected with some credential you might need to create credential that is associated to data source.\r\n",
                "\r\n",
                "Once you have properly configures data source, you can use it in `OPENROWSET` function:"
            ],
            "metadata": {
                "azdata_cell_guid": "4e487b5a-657a-4c2d-b24c-d9c755d27e4c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "select top 10 *\r\n",
                "from openrowset(\r\n",
                "        bulk 'latest/ecdc_cases.parquet',\r\n",
                "        data_source = 'covid',\r\n",
                "        format = 'parquet'\r\n",
                "    ) as rows"
            ],
            "metadata": {
                "azdata_cell_guid": "6ab5dd60-2dfe-4c19-a390-0c1505b0bde9"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Explicitly specify schema\n",
                "\n",
                "`OPENROWSET` enables you to explicitly specify what are the types of the columns that you want to read from the file using `WITH` clause:"
            ],
            "metadata": {
                "azdata_cell_guid": "c4145b77-8663-4e59-914b-721955a02635"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "select top 10 *\r\n",
                "from openrowset(\r\n",
                "        bulk 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.parquet',\r\n",
                "        format = 'parquet'\r\n",
                "    ) with ( date_rep date, cases int, geo_id varchar(6) ) as rows"
            ],
            "metadata": {
                "azdata_cell_guid": "f3da158c-c168-45b0-8e38-7ee2d430420f"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "PARQUET data types are by default mapped to SQL types. The following table describes how Parquet types are mapped to SQL native types.\n",
                "\n",
                "| Parquet type | Parquet logical type (annotation) | SQL data type |\n",
                "| --- | --- | --- |\n",
                "| BOOLEAN |  | bit |\n",
                "| BINARY / BYTE\\_ARRAY |  | varbinary |\n",
                "| DOUBLE |  | float |\n",
                "| FLOAT |  | real |\n",
                "| INT32 |  | int |\n",
                "| INT64 |  | bigint |\n",
                "| INT96 |  | datetime2 |\n",
                "| FIXED\\_LEN\\_BYTE\\_ARRAY |  | binary |\n",
                "| BINARY | UTF8 | varchar \\*(UTF8 collation) |\n",
                "| BINARY | STRING | varchar \\*(UTF8 collation) |\n",
                "| BINARY | ENUM | varchar \\*(UTF8 collation) |\n",
                "| BINARY | UUID | uniqueidentifier |\n",
                "| BINARY | DECIMAL | decimal |\n",
                "| BINARY | JSON | varchar(max) \\*(UTF8 collation) |\n",
                "| BINARY | BSON | varbinary(max) |\n",
                "| FIXED\\_LEN\\_BYTE\\_ARRAY | DECIMAL | decimal |\n",
                "| BYTE\\_ARRAY | INTERVAL | varchar(max), serialized into standardized format |\n",
                "| INT32 | INT(8, true) | smallint |\n",
                "| INT32 | INT(16, true) | smallint |\n",
                "| INT32 | INT(32, true) | int |\n",
                "| INT32 | INT(8, false) | tinyint |\n",
                "| INT32 | INT(16, false) | int |\n",
                "| INT32 | INT(32, false) | bigint |\n",
                "| INT32 | DATE | date |\n",
                "| INT32 | DECIMAL | decimal |\n",
                "| INT32 | TIME (MILLIS ) | time |\n",
                "| INT64 | INT(64, true) | bigint |\n",
                "| INT64 | INT(64, false ) | decimal(20,0) |\n",
                "| INT64 | DECIMAL | decimal |\n",
                "| INT64 | TIME (MICROS / NANOS) | time |\n",
                "| INT64 | TIMESTAMP (MILLIS / MICROS / NANOS) | datetime2 |\n",
                "| [Complex type](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#lists \"https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#lists\") | LIST | varchar(max), serialized into JSON |\n",
                "| [Complex type](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#maps \"https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#maps\") | MAP | varchar(max), serialized into JSON |"
            ],
            "metadata": {
                "azdata_cell_guid": "745b2c81-01eb-4bf5-9cad-47a03dcff194"
            }
        }
    ]
}